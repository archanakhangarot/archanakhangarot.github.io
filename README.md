# Data Scientist

#### Profile: Overall 8.5 years of IT experience with 6 years of experience in data science space specializing in the development and deployment of cutting-edge Generative AI and Large Language Models using Langchain. Proven expertise in building innovative NLP and AI solutions to drive business value. Proficient in data visualization and analysis using Pandas, Matplotlib, and Plotly. Experience in architecting Artificial Intelligence applications with Machine Learning, Deep Learning with Python and Fast API following a Test-Driven development.

#### Technical Skills: GenAI, LLM, DL, ML, Python,Langchain, Autogen, Chroma DB, Neo4j, SolrDB, MySQL, FastAPI, Flask, ML flow, GIT                          

## Education
- PGP, AI & ML | Greate Lakes University (2018-2019)
- BTech, Computer Science | Rajasthan Technical University (2010-2014)							       		

## Work Experience
**Senior Data Scientist @ Wolters Kluwer (_December 2021 - Present_)**

## Projects

### Actionable Invoice Summary
- Designed and implemented a pipeline for extracting tasks, activities, and personnel from retrieved invoices in the database, leveraging traditional NLP techniques and a GPT-based pipeline. The extracted data was visualized in the UI using a Tree map for intuitive representation.
- Developed a conversational chatbot to interact with past invoices and matters stored in the Solr database, utilizing agents through an agentic framework Autogen defined for various tasks
### UTBMS Task Code Recommender
- Built and deployed an end-to-end UTBMS Task Code Prediction pipeline, automating the classification of legal billing lines into task codes, significantly improving operational efficiency for a legal client.
- Designed a scalable, multi-step and multi-classification machine learning pipeline using advanced models like Random Forest and XGBoost, handling over 100,000 billing line items per run.
- Implemented a dynamic configuration framework where key pipeline parameters are fetched from a database, reducing hardcoding and enabling easy updates.
- Delivered actionable insights and improved model reliability by ensuring compatibility with existing LBA-DS architecture, facilitating seamless integration into the organization’s ecosystem.
### LBA AI (LLM)
- Created a data preparation and sampling strategy using K-Means Clustering, along with an algorithm designed to identify and extract dissimilar and unique lines stored as Knowledge Graph using Neo4j.
- Implemented a RAG (Retrieval-Augmented Generation) pipeline integrated with Chroma DB, utilizing well-crafted prompt engineering for enhanced performance.
### LBA AI (DS)
- Developed & integrated Random Forest and Logistic Regression for Travel Module, following extensive feature engineering and exploratory data analysis (EDA).
- Developed 15+ custom components for multiple clients using Python and NLP techniques across 6+ modules from LBA-DS.

### FN Reporting tool
- Developed and deployed a comprehensive FN Reporting tool to classify and predict module names for legal billing adjustments, enabling operational teams to identify and reduce false negatives (FNs) effectively.
- Built a database schema and dynamic configuration framework to seamlessly handle diverse module data and fetch key parameters, eliminating hardcoding for maintainability and flexibility.
- Automated data processing workflows and integrated email reporting to provide bi-weekly and quarterly FN summaries to module owners, enhancing transparency and actionable insights.

**Data Scientist @ Infosys (_June 2018 - December 2021_)**
## Projects

### FEDEX
- Worked on algorithmic approach of a Python and Apache-Spark-based exploration of how to predict an en-route package’s delivery date and potential delay status. Both the Delays and EDD models leverage the Fingerprint and Risk tables developed by DataWorks.
- A series of data transformations, conditional logic, and statistical thresholds are used to approximate the EDD and potential delay of packages.
- Used various bagging and boosting techniques in Python and Pyspark for classification modeling purpose.
- This development project is part of FedEx DataWorks’s longer term goal of developing an operating-company-agnostic learning model that has high coverage of the total package population and which has performance that surpasses current approaches.
### GEICO
- Built and deployed 7 response models, these were state response model about capturing the probability that a customer will respond to direct postal mailing for Insurance Client.
- Designed and developed customer segmentation model using Kmeans clustering where roughly 85% of US population is segmented to 6 different clusters after analyzing 1600 different variables.
- Gave recommendations to campaign strategy team by providing different cuts of insights to help them effectively strategize on marketing activities.


**Data Analyst @ Accenture (_May 2015 - Mar 2018_)**
- Responsible for data ingestion to target after Data validation and data cleaning.
- Designing dataflows for Data cleansing, transformation & migration leveraging Apache NiFi.
- Have done text translation and extensive cleaning of text data before feeding to NLP pipeline.
- Designed and developed different nth level strategy to understand the reason for negative experience.
